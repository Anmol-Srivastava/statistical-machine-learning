{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Submission for: Anmol Srivastava*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient Computation*\n",
    "\n",
    "When $n,d=1,$ the objective function and its gradient are:\n",
    "\n",
    "\\begin{equation}\n",
    "F(\\beta)= \\exp(-yx\\beta) + \\lambda\\beta^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla F(\\beta) = -yx \\exp(-yx\\beta) + 2\\lambda\\beta\n",
    "\\end{equation}\n",
    "\n",
    "We expand to the $n,d>1$ case:\n",
    "\n",
    "\\begin{equation}\n",
    "F(\\beta)= \\frac{1}{n}\\sum_{i=1}^{n}{\\exp(-y_ix_i^T\\beta)} + \\lambda\\|\\beta\\|^2_2\n",
    "\\end{equation}\n",
    "\n",
    "Using the linearity of differentiation, and other properties, we have:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla F(\\beta)= \\frac{1}{n}\\sum_{i=1}^{n}{\\nabla(\\exp(-y_ix_i^T\\beta))} + \\nabla(\\lambda\\|\\beta\\|^2_2)\n",
    "\\end{equation}\n",
    "\n",
    "By chain rule and properties of vector differentiation, we simplify:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla F(\\beta)= \\frac{-1}{n}\\sum_{i=1}^{n}{(y_ix_i)\\exp(-y_ix_i^T\\beta)} + 2\\lambda\\beta\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Processing (see code)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "PREFIX = 'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.'\n",
    "\n",
    "# loading \n",
    "spam = pd.read_csv(PREFIX + 'data', sep=' ', header=None)\n",
    "splits = pd.read_csv(PREFIX + 'traintest', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split \n",
    "merged = spam.merge(splits, left_index=True, right_index=True)\n",
    "merged[57] = merged[57].apply(lambda x: 1 if x==1 else -1)\n",
    "\n",
    "train = merged[merged['0_y'] == 0]\n",
    "test = merged[merged['0_y'] == 1]\n",
    "\n",
    "X_train = train.iloc[:,:-2]\n",
    "X_test = test.iloc[:, :-2]\n",
    "\n",
    "y_train = train.iloc[:, -2]\n",
    "y_test = test.iloc[:, -2]\n",
    "\n",
    "# standardize \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Function Definitions (see code, hyperparamsearch is in later section)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FUNCTION DEFINITIONS, hyperparamsearch() IS IN LATER SECTION \"\"\"\n",
    "\n",
    "def obj(B, lmbda, X, y):\n",
    "    risk = (1/len(y)) * np.sum(np.exp(-y*np.dot(X,B)))\n",
    "    penalty = lmbda * np.linalg.norm(B)**2\n",
    "    return risk + penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(B, lmbda, x, y):\n",
    "    yx = y[:,np.newaxis]*x\n",
    "    risk = (-1/len(y)) * np.sum(yx * np.exp(-np.dot(yx,B[:,np.newaxis])))\n",
    "    penalty = 2*lmbda*B\n",
    "    return risk + penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(B, lmbda, eta=1, alpha=0.5, gamma=0.8, T=100, X=X_train, y=y_train):\n",
    "    grad_B = grad(B, lmbda, X, y)\n",
    "    norm_grad_B = np.linalg.norm(grad_B)\n",
    "    finished_bt = False \n",
    "    t = 0 \n",
    "    \n",
    "    while (not finished_bt) and (t < T):\n",
    "        if obj(B-eta*grad_B, lmbda, X, y) < obj(B, lmbda, X, y) - alpha*eta*norm_grad_B**2:\n",
    "            finished_bt = True \n",
    "        elif t == T:\n",
    "            raise \"Exceeding 100 iterations of backtracking line search.\"\n",
    "        else:\n",
    "            eta *= gamma\n",
    "            t += 1\n",
    "    \n",
    "    return eta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myclassifier(epsilon, lmbda, X=X_train, y=y_train):\n",
    "    w, v = np.linalg.eigh((1/len(y)) * np.dot(X.T, X))\n",
    "    eta_init = 1 / (max(w) + lmbda) \n",
    "\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    theta = np.zeros(X.shape[1])   \n",
    "\n",
    "    grad_theta = grad(theta, lmbda, X, y)\n",
    "    grad_beta = grad(beta, lmbda, X, y)\n",
    "\n",
    "    beta_vals = beta \n",
    "    t = 0 \n",
    "    \n",
    "    while np.linalg.norm(grad_beta) > epsilon and t < 1000: \n",
    "        eta = backtracking(beta, lmbda, eta=eta_init) \n",
    "        beta_new = theta - eta*grad_theta \n",
    "        theta = beta_new + (t/(t+3)) * (beta_new-beta)\n",
    "        \n",
    "        beta = beta_new \n",
    "        beta_vals = np.vstack((beta_vals, beta))\n",
    "        grad_theta = grad(theta, lmbda, X, y)\n",
    "        grad_beta = grad(beta, lmbda, X, y)\n",
    "        t += 1 \n",
    "    \n",
    "    return beta_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training ($\\epsilon=0.005, \\lambda=1$)*\n",
    "\n",
    "*__Please Note:__* \n",
    "\n",
    "Error is reported below. As we can see, for a binary classification problem our error rates are high. An investigation of the code reveals that the primary issue is the amount by which the weights change in *myclassifier.* \n",
    "\n",
    "Specifically, the algebraic terms in the algorithm resulted in extremely small changes in $\\beta$ from iteration to iteration. These negligible movements in $\\beta$ (on a $10^{-10}$ scale) meant that the objective function is not converging towards a minimum at a fast enough rate. So, when *myclassifier* terminates, even the training error will be high. It was difficult to resolve this coding issue, after multiple modifications to the algorithm (randomizing initial weights, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TRAINING & TUNING \"\"\"\n",
    "\n",
    "# lambda=1, epsilon=0.005\n",
    "Bs = myclassifier(0.005, 1)\n",
    "B = Bs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When lambda = 1,\n",
      "Misclassification Error, Training Data: 34.58%\n",
      "Misclassification Error, Testing Data: 33.27%\n"
     ]
    }
   ],
   "source": [
    "# misclassification error\n",
    "def misclassification_error(B, X, y):\n",
    "    err = 0\n",
    "    y = y if isinstance(y, np.ndarray) else y.to_numpy()\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if np.sign(np.dot(X[i], B)) != y[i]:\n",
    "            err += 1\n",
    "\n",
    "    return err/len(y) \n",
    "\n",
    "mc_err_train = 100 * misclassification_error(B, X_train, y_train)\n",
    "mc_err_test = 100 * misclassification_error(B, X_test, y_test)\n",
    "\n",
    "print('When lambda = 1,')\n",
    "print('Misclassification Error, Training Data: %.2f%%' % mc_err_train)\n",
    "print('Misclassification Error, Testing Data: %.2f%%' % mc_err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Grid-Search ($\\lambda$)*\n",
    "\n",
    "We re-group the data and create the desired 60%-40%split between training and validation data. We then use grid search on the validation set, via a logarithmic scale for $\\lambda$, and report our findings. Note that as before, the unresolved issue of minute changes in $\\beta$ hinder the performance of *myclassifier* and the resulting grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of lambda: 0.001. For this lambda,\n",
      "Misclassification error is: 34.17%\n",
      "Sensitivity (in the validation set) is: 54.50%\n",
      "Specificity (in the validation set) is: 73.35%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# grid search for lambda with 60/40 split for training/val\n",
    "def hyperparamsearch():\n",
    "    \n",
    "    # limited range due to time-efficiency concerns \n",
    "    scale = np.logspace(-3, 0, 4)\n",
    "    optimal_lambda = 0 \n",
    "    optimal_err = 1\n",
    "    optimal_B = None\n",
    "    \n",
    "    # merge and split data \n",
    "    X = np.concatenate((X_train, X_test))\n",
    "    y = np.concatenate((y_train, y_test))\n",
    "    xtrn, xval, ytrn, yval = train_test_split(X, y, train_size=0.6)\n",
    "    \n",
    "    # search via validation data\n",
    "    for lmbda in scale: \n",
    "        B = myclassifier(epsilon, lmbda, xtrn, ytrn)[-1]\n",
    "        err = misclassification_error(B, xval, yval)\n",
    "        \n",
    "        if err < optimal_err:\n",
    "            optimal_lambda = lmbda\n",
    "            optimal_err = err \n",
    "            optimal_B = B\n",
    "    \n",
    "    # remaining metrics\n",
    "    TP = 0\n",
    "    TN = 0 \n",
    "    \n",
    "    for i in range(len(yval)):\n",
    "        if np.sign(np.dot(xval[i], optimal_B)) == 1 and yval[i] == 1:\n",
    "            TP += 1\n",
    "        elif np.sign(np.dot(xval[i], optimal_B)) == -1 and yval[i] == -1:\n",
    "            TN += 1\n",
    "        else:\n",
    "            pass \n",
    "    \n",
    "    sens = 100*TP / len(yval[yval == 1]) \n",
    "    spec = 100*TN / len(yval[yval == -1])\n",
    "    main = 100*optimal_err \n",
    "    \n",
    "    print('Optimal value of lambda: %g. For this lambda,' % optimal_lambda)\n",
    "    print('Misclassification error is: %.2f%%' % main)\n",
    "    print('Sensitivity (in the validation set) is: %.2f%%' % sens)\n",
    "    print('Specificity (in the validation set) is: %.2f%%' % spec)\n",
    "    \n",
    "hyperparamsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Contagion*.\n",
    "\n",
    "It appears impossible to estimate the sensitivity and specificity of the antibody test. Sensitivity is the \"true positive rate,\" given positive test results and total positive instances. Similarly, specificity is the \"true negative rate\" given negative test results and total negative instances. To estimate both, it is necessary to know which samples were \"actually\" positive (had antibodies). We are given only the samples which \"tested\" positive (and by extension, those which tested negative). Without the \"true\" counts of total positive or negative instances, Sharon and Billie will be unable to determine the specificity or sensitivity accurately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Flying saucers*.\n",
    "\n",
    "With UFOs, we must consider that there are a lot of legitimate objects in the sky that might not be discernible by the naked eye or image/video capture. Many planes (at various altitudes), birds, cloud formations, and light effects can be mistaken as UFOs (or deliberately distorted by conspiracy theorists). It is hence important to determine whether a detector is fake by its ability to correctly identify \"negative\" examples. That is, we care more about its ability to correctly yield negative results for the frequent non-saucers, than to \"positively\" classify the rare aliens. Even though we are in contact with an alien, the probabilistic likelihood of alien appearances has historically been low. Therefore, we use *__specificity__* (true negative rate over all negative samples) as the chief performance metric. Sensitivity may still have lesser value, as it is important to notice the rare occasion on which an alien is present. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
